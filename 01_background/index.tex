\chapter{Background}
\label{chap:Background}

\section{Introduction}

The field of multi-FPGAs has been heavily researched however there are few papers interested in utilising HLS to streamline the process of implementing a multi-FPGA. \cite{564741} and \cite{707888} are examples of papers which do concern themselves with these topics but both were written over twenty years ago.

Therefore, it is of interest to this project to do a review of the most up to date research in fields surrounding and including its scope. This chapter will go through four different topics:

\begin{itemize}
    \item Related works.
    \item HLS tools and their optimisations.
    \item FPGA-to-FPGA communication protocols.
    \item Multi-FPGA Logic Partitioning.
\end{itemize}

Thus, hopefully, giving the reader a better overview of what is possible if this project were to reach its full potential.

\section{Related Work}

As previously mentioned, \cite{564741} and \cite{707888} are papers which have already attempted to solve the issues raised by this project. The solution in the former uses the GNU C++ compiler as well as a method of describing the algorithm as a set of difference equations. One point the authors explicitly state is that they utilise C++'s operator overloading feature in order to map software operations to specific hardware modules. Nonetheless, once the circuit has been generated, it is then automatically partitioned using a method based on Fiducia-Mattheyses bi-partitioning heuristic \cite{1585498} with the goal of this stage to maximise logic utilisation in each FPGA as well as minimising IO consumption.

The method by which the FPGAs communicated with each other is not discussed in the paper, all that is mentioned is the method used for partitioning. There is, however, mention of a host CPU, and it may be reasonable to assume that this CPU acts as a master for all FPGAs meaning there is no direct communication between FPGAs.

The latter paper, \cite{707888}, opts to place a psuedo-processor on each FPGA within the topology and then have a top-level controller supply each FPGA with the instructions it is meant to execute. The HLS aspect then merely needs to convert the supplied source code into a list of instruction which is the intended use of standard compilers. The motivation for this approach was to make multi-FPGA systems more accessible to software developers, which is its main target demographic. Alongside this, the paper also presents how it uses a 4 dimensional space, with one dimension being each FPGA system, to optimise the datapath of the system. This then supposedly creates a control path where the FPGAs are used in parallel wherever possible.

\section{HLS Tools \& Optimisations}

\subsection{Introduction}

Different HLS tools have vastly different implementations \cite{7368920} and many of them, especially commercial tools, do not reveal their methodologies. \cite{legup} for example, compiles the input source code using the LLVM compiler and then profiles it on a modified MIPS CPU emulator in order identify which parts of the code would benefit from hardware acceleration. It then synthesis those specific parts to dedicated hardware, while the rest of the code is run using a MIPS CPU programmed onto the FPGA.

Vivado HLS, on the other hand, makes no attempt to suggest to the user where acceleration is possible. Rather, it merely gives you tools known as PRAGMAS, found in \cite{vivado-optmisation-manual}, to help the compiler better understand how to convert the C code to hardware. The output is then a set Verilog files the user can implement as they see fit, though it is recommended to use the Vivado Design Suite \cite{vivado-design-suite-manual} as part of the development cycle. As of now, Vivado has not revealed how they go from C to Verilog.

A third contender is Bambu~\cite{6645550}, which leverages the GCC IR in order to optimise the resulting hardware and focuses mainly on memory intensive programs. In short, each implementation has its own intended purpose and thus excels in a specific area, but the fact that there are many implementations indicate that this field has much room from improvement and is actively under development.

\subsection{Input Language}

For the most part, HLS tools tend be based around compiling a subset of C or C++ to Verilog \cite{7368920}, however, there is an argument to be made that functional programming languages have a certain affinity towards hardware development. \cite{bjesse1998lava} presents an early form of the idea, Lava, which takes Haskell as input and produces circuit specifications. The tool was built in the early days of HDLs, and thus was intended to be a competitor rather than a part of the tool chain. More modern approaches such as \cite{hardcaml} are libraries for existing languages and instead produce Verilog or SystemVerilog which can be later synthesised by the appropriate tools. But why bother with straying so far from the norm. Well in \cite{7331371}, it is suggested that the firm mathematical founding in which functional languages are based can assist in verifying hardware designs as well as offering benefits such as recursive functions and type inference. While the author in \cite{Edwards2019FHWP}, suggests that the functional paradigm can allow for a greater exploitation of parallelism, one of the driving reason to using FPGAs. 

Evidently, the field of research in using functional languages is of interest to quite a few individuals. \cite{7723553} lists a few papers in its introduction whilst also contributing to the field itself, but it has yet to be seen whether Functional HLS will overtake standard C-based HLS anytime soon.

\subsection{Loop Pipelining}

One of the major benefits of running a system on an FPGA is its ability to perform computation in parallel. Loop pipelining is a perfect example of this, where a HLS tool will take a for loop or while loop written in the source code and run segments of it concurrently in order to reach a low initiation interval(II). Page 120 of \cite{vivado-optmisation-manual} and page 11 of \cite{intel-hls-manual} show how the two leading HLS tools, Vivado HLS and Intel High Level Synthesis Compiler, implement pipelining respectively. The II is a measure of how many a new iteration of the loop can start and a lower value, ideally one, means that the section of code containing the loop will be computed faster. 

There are issues, however, with attempting to reach an $II = 1$. \cite{7544750} explores how memory dependencies, two parts of a loop accessing the same memory resources, can cause increases in II due to the HLS compiler not being able to find a way to resolve these dependencies. Instead, is proposes the idea of splitting loops in order to reach an II of 1 on each of these sub-loops and then to pipe the data from one sub-loop to the next. Another approach show in \cite{7160061} opts to implement parametric hardware to resolve similar dependencies. 

In summary, for simple programs with static loop behaviour the loop pipelining strategies found in commercial tools is very effective and likely the most important optimisation. However, when the behaviour becomes uncertain more effort is required on the user's side to help the compiler reach lower II's.

\subsection{Data Streaming}

In order to process data in parallel on an FPGA the data must first be available to the device or module doing the processing, an obvious point but one that must be considered for any HLS system. In general, there are two approaches to solve the problem of ensuring data availability, the first is atomic transactions while the second is data streaming/dataflow. Say that we have two modules, $A$ and $B$ which are connected such that the output of $A$, which is an array, is the input of $B$. Let us also say that both modules iterate over an array doing some processing, i.e. multiplying the elements by 2 or adding 5, on said array. In an atomic system we would first let $A$ iterate over the entire array and then pass the array to $B$ and allow it to compute its function. 

In this case, even though the modules themselves may be pipelined there isn't much parallelism being exploited on the module level. $B$ is sitting idle for the entire time $A$ is operating and vice-versa. The solution to this is dataflow, which is where every time $A$ completes an iteration it then passes that data to $B$ allowing to start its computation. This results in both modules being utilised at the same time and reduces the overall latency of the system. Section 3.3 of \cite{9264692} explores further, why a user might opt for this method and the considerations they must take if they choose to do so. 

In relation to HLS tools, this optimisation is pivotal to achieving high throughput in any system that operators on large amount of data. Pages 20-24, 95-97 and 126-128 of \cite{vivado-optmisation-manual} show how Vivado HLS allows its users to access such functionality.






